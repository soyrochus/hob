# Architecture Baseline â€” Hob

> **Status**: Baseline documentation of the application as it currently stands, before Hob-specific modifications.
>
> This application is a fork of [OpenAI's Realtime API Agents Demo](https://github.com/openai/openai-realtime-agents), used under the MIT license and being adapted into a new product called **Hob**.

---

## 1. Overview

Hob is a **voice-first multi-agent application** built on the OpenAI Realtime API. It enables low-latency, streaming voice conversations with AI agents that can call tools, hand off between each other, and be supervised by higher-intelligence text-based models. The current codebase contains three functional demo scenarios that showcase different agent architecture patterns.

### Technology Stack

| Layer | Technology |
|-------|-----------|
| Framework | Next.js 15.3.1 (App Router) |
| Language | TypeScript (strict mode) |
| UI | React 19, Tailwind CSS |
| Agent Orchestration | `@openai/agents` v0.0.5 (OpenAI Agents SDK) |
| Voice Transport | WebRTC via OpenAI Realtime API |
| Text Intelligence | OpenAI Responses API (gpt-4.1, gpt-4o-mini) |
| Schema Validation | Zod |
| State Management | React Context API |

---

## 2. Top-Level Project Structure

```
/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ App.tsx                  # Root client component
â”‚       â”œâ”€â”€ page.tsx                 # Next.js page; wraps App in context providers
â”‚       â”œâ”€â”€ layout.tsx               # Root HTML layout
â”‚       â”œâ”€â”€ types.ts                 # Core TypeScript enums and interfaces
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ session/route.ts     # Creates ephemeral OpenAI Realtime sessions
â”‚       â”‚   â””â”€â”€ responses/route.ts   # Proxy to OpenAI Responses API
â”‚       â”œâ”€â”€ agentConfigs/            # All agent scenario definitions
â”‚       â”œâ”€â”€ components/              # React UI components
â”‚       â”œâ”€â”€ contexts/                # React Context providers
â”‚       â”œâ”€â”€ hooks/                   # Custom React hooks
â”‚       â””â”€â”€ lib/                    # Utility functions
â”œâ”€â”€ docs/                            # Documentation (this file lives here)
â”œâ”€â”€ ORIG_OPENAI_README.md            # Original OpenAI demo README
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

---

## 3. Runtime Architecture

### 3.1 Session Lifecycle

```
Browser                     Next.js Server              OpenAI
  â”‚                               â”‚                        â”‚
  â”‚â”€â”€ GET /api/session â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                        â”‚
  â”‚                               â”‚â”€â”€ POST /realtime/sessions â”€â”€>â”‚
  â”‚                               â”‚<â”€â”€ ephemeral key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚<â”€â”€ { client_secret } â”€â”€â”€â”€â”€â”€â”€â”€â”‚                        â”‚
  â”‚                               â”‚                        â”‚
  â”‚â”€â”€ WebRTC negotiation (SDP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚<â”€â”€ audio stream (bidirectional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
```

1. The browser calls `GET /api/session`, which forwards to OpenAI and returns a short-lived ephemeral key (1 hour TTL).
2. The browser uses that key to establish a **WebRTC peer connection** directly with OpenAI's Realtime API â€” audio is end-to-end encrypted and does not pass through the Next.js server.
3. All subsequent intelligence (agent responses, tool calls, handoffs) streams back over the same WebRTC connection.

### 3.2 Supervisor (Text API) Flow

For scenarios where more intelligence is needed than a realtime model provides, the chatSupervisor pattern routes requests through a second path:

```
Browser                     Next.js Server              OpenAI
  â”‚                               â”‚                        â”‚
  â”‚â”€â”€ POST /api/responses â”€â”€â”€â”€â”€â”€â”€>â”‚                        â”‚
  â”‚   { messages, tools }         â”‚â”€â”€ Responses API â”€â”€â”€â”€â”€â”€>â”‚
  â”‚                               â”‚   (gpt-4.1, tool loop) â”‚
  â”‚                               â”‚<â”€â”€ text response â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚<â”€â”€ { output } â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                        â”‚
```

This endpoint proxies to the OpenAI Responses API and handles iterative tool-call loops server-side before returning the final text.

---

## 4. Agent Architecture

### 4.1 Agent Definition Model

All agents are instances of `RealtimeAgent` from the OpenAI Agents SDK. An agent is defined by:

```typescript
{
  name: string,                  // Unique identifier
  voice: string,                 // TTS voice selection (e.g. "sage")
  instructions: string,          // System prompt / persona
  tools: tool[],                 // Callable functions
  handoffs: RealtimeAgent[],     // Agents this agent can transfer to
  handoffDescription: string,    // Description shown to other agents when routing
}
```

### 4.2 The Three Demo Scenarios

The application ships with three distinct agent configurations, selectable via URL param (`?agentConfig=`) or a UI dropdown.

---

#### Scenario A: Simple Handoff (`simpleHandoff`)

The minimal reference implementation of agent-to-agent transfer.

```
greeterAgent â”€â”€handoffâ”€â”€> haikuWriterAgent
```

- `greeterAgent` introduces itself and asks if the user wants a haiku.
- On confirmation, it invokes a handoff, transferring the conversation to `haikuWriterAgent`.
- Demonstrates the core one-way handoff primitive.

---

#### Scenario B: Chat Supervisor (`chatSupervisor`)

A two-tier architecture that separates fast interaction from deep reasoning.

```
         User (voice)
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚  Chat Agent  â”‚   gpt-4o-realtime-mini
       â”‚  (realtime)  â”‚   Low latency, voice output
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ tool call: getNextResponseFromSupervisor()
              â”‚
         POST /api/responses
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚  Supervisor  â”‚   gpt-4.1 (text model)
       â”‚   Agent      â”‚   High intelligence, tool execution
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ tools
       â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                       â”‚
  lookupPolicy          getUserAccountInfo
  Document()            findNearestStore()
```

**Design rationale:**
- The realtime mini model handles greetings, fillers, and simple questions directly â€” low cost and low latency.
- Complex or policy-sensitive questions are forwarded (with full conversation history) to the text-based supervisor model, which can call tools iteratively and return a precise answer.
- The chat agent reads the supervisor's response verbatim to the user.
- Tool data is currently served from mock data (`sampleData.ts`).

---

#### Scenario C: Customer Service Retail (`customerServiceRetail`)

A fully-connected multi-agent network for a fictional snowboard retailer ("Snowy Peak Boards").

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                       â”‚
 authentication â”€â”€â”€â”€â”€â”€> returns <â”€â”€â”€â”€â”€â”€> sales
      â”‚                    â”‚                  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> simulatedHuman <â”€â”€â”€â”€â”€â”€â”€â”˜
```

All agents in this network can hand off to each other (bidirectional), with the exception of `authentication`, which is always the entry point.

| Agent | Responsibility | Notable Tools |
|-------|---------------|---------------|
| `authentication` | Verifies user identity via a state-machine prompt | â€” |
| `returns` | Order lookup, return eligibility, initiates returns | `lookupOrders`, `retrievePolicy`, `checkEligibilityAndPossiblyInitiateReturn` |
| `sales` | Product recommendations, promotions, checkout | `lookupNewSales`, `addToCart`, `checkout` |
| `simulatedHuman` | Escalation endpoint; represents a human representative | â€” |

The `returns` agent calls `o4-mini` for high-stakes eligibility decisions (a second-tier reasoning pattern within a single agent).

---

### 4.3 Tool Execution

Tools are defined with a Zod-compatible JSON schema and an `execute` function:

```
Agent generates text â”€â”€> SDK intercepts function_call
                              â”‚
                         execute() runs locally
                              â”‚
                         Result injected back into conversation
                              â”‚
                         Agent continues
```

Tools execute **in the browser process** for realtime agents, or **on the server** (via `/api/responses`) for supervisor agents.

---

## 5. Voice & Audio System

### 5.1 Transport

- Audio uses **WebRTC** (`RTCPeerConnection`) via `OpenAIRealtimeWebRTC` from the SDK.
- Remote audio is rendered through a hidden `<audio>` element injected into the DOM.
- Codec negotiation is configurable: **opus 48kHz** (default, high quality) or **PCMU/PCMA 8kHz** (narrow-band, PSTN simulation).

### 5.2 Voice Activity Detection (VAD)

The default mode uses server-side VAD, configured with:

| Parameter | Value |
|-----------|-------|
| Threshold | 0.9 |
| Prefix padding | 300 ms |
| Silence duration | 500 ms |

An alternative **Push-to-Talk (PTT)** mode is available via a UI toggle, replacing VAD with explicit button-hold interaction.

### 5.3 Transcription

User speech is transcribed by `gpt-4o-mini-transcribe`. Transcription deltas stream in real time and are accumulated into the transcript UI. Unparseable audio falls back to `[inaudible]`.

### 5.4 Audio Recording & Download

The application can record the full conversation (both sides) by:
1. Merging the microphone stream and the remote audio stream via the Web Audio API (`AudioContext`).
2. Recording as WebM with `MediaRecorder`.
3. Converting the WebM blob to WAV on download via `audioUtils.ts`.

---

## 6. State Management

### 6.1 Context Providers

State is managed via two React Context providers, both mounted at the `page.tsx` level.

**TranscriptContext** â€” owns the conversation UI model:

| Item type | Description |
|-----------|-------------|
| `MESSAGE` | A user or assistant utterance, with streaming-safe delta updates |
| `BREADCRUMB` | A metadata annotation (tool call, handoff, guardrail event) |

Key operations: `addTranscriptMessage`, `updateTranscriptMessage`, `addTranscriptBreadcrumb`, `toggleExpand`, `updateTranscriptItem`.

**EventContext** â€” owns the developer event log:
- Logs all SDK events with direction (`â¬†` client-originated, `â¬‡` server-originated).
- Each entry is expandable to its raw JSON payload.
- Used exclusively by the `Events.tsx` debug panel.

### 6.2 Session State (local to App.tsx)

| State variable | Type | Purpose |
|----------------|------|---------|
| `sessionStatus` | `DISCONNECTED \| CONNECTING \| CONNECTED` | Connection lifecycle |
| `selectedAgentConfigSet` | `RealtimeAgent[]` | Active agent scenario |
| `selectedAgentName` | `string` | Currently active agent in session |
| `isPTTActive` | `boolean` | PTT mode enabled |
| `isPTTUserSpeaking` | `boolean` | User holding PTT button |

### 6.3 Persistent Preferences (localStorage)

| Key | Stored value |
|-----|-------------|
| `pushToTalkUI` | PTT mode preference |
| `logsExpanded` | Event panel open/closed |
| `audioPlaybackEnabled` | Speaker output on/off |

---

## 7. Output Guardrails

Every assistant message is passed asynchronously through a moderation step powered by `gpt-4o-mini`:

```
Assistant message completes
        â”‚
  POST /api/responses (guardrail prompt)
        â”‚
  gpt-4o-mini classifies text
        â”‚
  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ NONE   OFFENSIVE   OFF_BRAND   VIOLENCE â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
  Result stored in transcript item
        â”‚
  GuardrailChip UI updates (pending â†’ pass/fail)
        â”‚
  If triggered: corrective message injected into conversation
```

The moderation prompt is parameterized by `companyName` for brand-specific customization.

---

## 8. UI Layer

### 8.1 Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Scenario â–¼]  [Agent â–¼]                        â”‚  â† Top bar
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                          â”‚                      â”‚
â”‚      Transcript          â”‚     Events Log       â”‚
â”‚   (messages + crumbs)    â”‚  (SDK event stream)  â”‚
â”‚                          â”‚                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Connect/Disconnect]  [PTT â–¡]  [ğŸ”Š]  [Codec â–¼] â”‚  â† Bottom toolbar
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Components

| Component | File | Responsibility |
|-----------|------|---------------|
| `App` | `App.tsx` | Root layout, session orchestration, event wiring |
| `Transcript` | `Transcript.tsx` | Message bubbles, breadcrumbs, text input, auto-scroll |
| `Events` | `Events.tsx` | Collapsible raw event log with JSON drill-down |
| `BottomToolbar` | `BottomToolbar.tsx` | Connection controls, PTT, audio, codec selector |
| `GuardrailChip` | `GuardrailChip.tsx` | Inline moderation status per message |

---

## 9. Key Hooks

| Hook | File | Responsibility |
|------|------|---------------|
| `useRealtimeSession` | `hooks/useRealtimeSession.ts` | Manages the SDK `RealtimeSession`; handles connect/disconnect, audio element creation, codec negotiation, PTT events |
| `useHandleSessionHistory` | `hooks/useHandleSessionHistory.ts` | Subscribes to SDK history events and translates them into context updates (transcript items, breadcrumbs, event log entries) |
| `useAudioDownload` | `hooks/useAudioDownload.ts` | Merges and records audio streams; exposes download handler |

---

## 10. API Routes

| Route | Method | Purpose |
|-------|--------|---------|
| `/api/session` | GET | Creates an OpenAI Realtime session and returns the ephemeral client secret |
| `/api/responses` | POST | Proxies to the OpenAI Responses API; runs iterative tool-call loops for supervisor and guardrail calls |

Both routes require `OPENAI_API_KEY` in the environment.

---

## 11. Data Flow Summary

### Voice input â†’ transcript

```
Microphone â†’ WebRTC â†’ OpenAI VAD â†’ transcription deltas
                                        â†’ handleTranscriptionDelta()
                                        â†’ TranscriptContext (MESSAGE, streaming)
```

### Agent response â†’ audio + transcript

```
OpenAI generates response â†’ audio stream â†’ <audio> element â†’ speaker
                         â†’ transcript delta â†’ TranscriptContext (MESSAGE, streaming)
                         â†’ [guardrail check] â†’ GuardrailChip
```

### Tool call

```
Agent emits function_call â†’ SDK captures â†’ tool.execute() runs
                                         â†’ result injected into history
                                         â†’ EventContext (breadcrumb)
                                         â†’ agent continues
```

### Agent handoff

```
Agent calls transfer_to_{agent} â†’ SDK routes session to new agent
                                â†’ EventContext (breadcrumb: "handoff")
                                â†’ App.tsx updates selectedAgentName
```

---

## 12. Configuration & Build

- **TypeScript**: strict mode, target ES2017, path alias `@/*` â†’ `./src/*`
- **Tailwind CSS**: utility classes, no custom theme configuration
- **Environment variable**: `OPENAI_API_KEY` (required)
- **Dev server**: `npm run dev` (Next.js on port 3000)
- **Agent scenario selection**: URL parameter `?agentConfig=<key>` or UI dropdown

### Agent Registry

Scenarios are registered in `src/app/agentConfigs/index.ts`:

```typescript
const allAgentSets = {
  simpleHandoff,          // Basic 2-agent handoff demo
  customerServiceRetail,  // Multi-agent retail customer service
  chatSupervisor,         // Two-tier realtime + text supervisor
};
const defaultAgentSetKey = 'chatSupervisor';
```

Adding a new scenario requires: creating a file exporting a `RealtimeAgent[]` array, then registering it in this map.

---

## 13. Notable Design Patterns

1. **Two-tier agent architecture** â€” cheap/fast realtime model for voice UX, expensive/smart text model for reasoning. Reduces cost and latency simultaneously.
2. **Supervisor tool iteration loop** â€” the `/api/responses` route runs tools in a loop until the model produces a final text response, server-side, before returning to the client.
3. **Breadcrumb pattern** â€” non-speech events (tool calls, handoffs, guardrail results) are embedded as collapsible metadata items in the transcript stream rather than in a separate log.
4. **State-machine prompting** â€” complex multi-step flows (e.g., authentication) are encoded as explicit states in the system prompt, with instructions for each transition.
5. **Async guardrails** â€” moderation runs after response completion and does not block audio playback; UI updates asynchronously.
6. **Codec negotiation** â€” SDP-level codec preference injection allows the same app to simulate PSTN-quality narrow-band audio for telephony testing.
